# .github/workflows/model-validation.yml
name: Model Validation

on:
  push:
    branches: [ main, master, develop ]
    paths:
      - 'src/models/**'
      - 'src/features/**'
      - 'src/data/**'
  pull_request:
    branches: [ main, master, develop ]
    paths:
      - 'src/models/**'
      - 'src/features/**'
      - 'src/data/**'

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Prepare test data and model
        run: |
          mkdir -p data/raw data/processed/test models/comparison/production
          echo "id,Gender,Age,HasDrivingLicense,RegionID,VehicleAge,PastAccident,AnnualPremium,SalesChannelID,DaysSinceCreated,Result" > data/raw/test.csv
          echo "1,Male,30,1,10,1-2 Year,No,1000,26,60,0" >> data/raw/test.csv

          # Create a properly fitted model
          python -c "import pickle; import numpy as np; from sklearn.ensemble import RandomForestClassifier; X = np.random.rand(100, 10); y = np.random.randint(0, 2, 100); model = RandomForestClassifier(n_estimators=10); model.fit(X, y); pickle.dump(model, open('models/comparison/production/production_model.pkl', 'wb'))"

          # In a real scenario, you might download test data from a secure location
          # For this example, we'll use dummy data from the repo
          # aws s3 cp s3://your-bucket/test-data.csv data/raw/test.csv


      - name: Run data processing pipeline
        run: python -m src.data.process_data --input data/raw/test.csv --output data/processed/test --no-splits

      - name: Validate model metrics
        run: |
          # Run a script that loads the model and evaluates it on test data
          python -m src.models.validate_model --data data/processed/test/processed_data.csv --threshold 0.5
